Impaler cloudier Impaler is an open-source software project it is created by cloud era it provides a database management system for data stored in a computer cluster running Apache Hadoop cloud or impaler is a query engine that runs on Apache Hadoop the project was announced in October 2012 with a public beta test distribution the Apache licensed impaler project brings scalable parallel database technology to Hadoop it enables users to assume low latency SQL queries to data stored in HDFS and Apache base without requiring data movement or transformation impaler is integrated with a dupe it uses the same file and date to formats metadata security and resource management frameworks as used by other components the components include Map Reduce Apache hive Apache pig and other Hadoop software Impaler is promoted for analysts and data scientists it is used to perform analytics on data stored in Hadoop via SQL or business intelligence tools the result is that large-scale data processing and interactive queries can be done on the same system using the same data and metadata this removes the need to migrate data sets into specialized systems or proprietary formats simply to perform analysis features include support for HDFS and Apache HBase storage reads Hadoop date formats supports Hadoop security role based authorization with sentry and uses metadata ODBC driver and SQL syntax from Apache hive in early 2013 a column-oriented data format called park' was announced for impaler in December 2013 Amazon Web Services announced support for Impaler thank you for watching for more videos please visit 0 fro training.com 

Apache Hadoop
Apache Hadoop is an open source framework that is used to efficiently store and process large datasets ranging in size from gigabytes to petabytes of data. Instead of using one large computer to store and process the data, Hadoop allows clustering multiple computers to analyze massive datasets in parallel more quickly.

Hadoop Distributed File System (HDFS)
HDFS (Hadoop Distributed File System) is the primary storage system used by Hadoop applications. This open source framework works by rapidly transferring data between nodes. 
HDFS is a distributed file system that handles large data sets running on commodity hardware. It is used to scale a single Apache Hadoop cluster to hundreds (and even thousands) of nodes. In HDFS data is distributed over several machines and replicated to ensure their durability to failure and high availability to parallel application. 


Impala is a MPP (Massive Parallel Processing) SQL query engine for processing huge volumes of data that is stored in Hadoop cluster. It provides high performance and low latency compared to other SQL engines for Hadoop. (Lower latency refers to a minimal delay in the processing of computer data over a network connection. )



Basically Impala is a SQL query engine for processing huge volumes of data that is stored in Hadoop cluster. So, to understand it better we have to know what is Hadoop. So, Hadoop is an open source framework that is used to efficiently store and process large datasets. So, Instead of using one large computer to store and process the data, Hadoop allows clustering of multiple computers to analyze massive datasets in parallel and more quickly. For example, if we are collecting data from Social Media...we will get different types of datas like Audio, Video, Text. So instead of storing all these different data types in one location it stores it in different locations and while analyzing, it analyze parallely all the datas which is much faster than other softwares.
So, Impala is a SQL query engine for data stored in Hadoop clusters. Impala is also known as (Massive Parallel Processing) SQL query engine. It provides high performance and low latency compared to other SQL engines for Hadoop. (Lower latency refers to a minimal delay in the processing of computer data over a network connection.)

Also, the advantages of Impala is that It has very Fast Speed. 
No need to Move Data. i.e Data Migration is not needed. In Impala the data processing is carried where the data resides (on Hadoop cluster), data transformation and data movement is not required for data stored on Hadoop
Also the data extract process is very short and easy.
Impala also recognizes Hadoop file formats like text, LZO, Avro, RCFile, Parquet.

But it also has few disadvantages also. In Impala, you cannot update or delete individual records. Impala does not support transactions and indexing. It cannot read cistom binary files. Whenever new records/files are added to the data directory in HDFS, the table needs to be refreshed.

So, if I have to compare Impala with Hive.
Impala is 6-69 times faster than Hive as it does not uses mapreduce algorithms. In Impala all the aspects of query execution run on the same machines. 
Hive takes time to start, whereas Impala avoids any possible startup overheads, to process a query Impala processes are started at the boot time itself.



Disadvantages is that Hive supports complex types, whereas Impala does not support.
During query execution if a data node goes down, Impala starts all over again. Whereas Hive is fault tolerant. i.e The output of the query will be produced.
For high complex queries performance of Hive is better than Impala.
