AWS Cloud Technical Essentials

Welcome to AWS Cloud Technical Essentials
Hey, everyone, I'm Morgan Willis, Senior Cloud Technologist at AWS, and I want to welcome you to this course. In this course, you will learn the key concepts behind cloud computing and explore AWS services using real life examples covering compute, networking, storage, databases, security and more. This course is intended for people working in IT or IT-related fields, who have a general knowledge of IT topics but have yet to learn much about the AWS cloud. To kick off this course, we will cover the basics of what the cloud is, the benefits of the cloud, the AWS Global Infrastructure, and Identity and Access Management. This will give you a solid foundation for learning the rest of the more technical topics contained in the course. 

Then we will focus on computing and for this topic, we will dig into services like Amazon Elastic Compute Cloud, AWS container services like Amazon Elastic Container Service and serverless compute options like AWS Lambda. Then we will discuss networking in AWS, using services like Amazon Virtual Private Cloud and other networking technologies used for creating, securing and connecting to your own private network in AWS. For storage, we'll explore how and when to use Amazon S3, Amazon Elastic Block Store and others. For databases, we will cover use cases around the many different database services AWS has to offer, but with a special focus on Amazon Relational Database Service, and Amazon DynamoDB. 

Then finally, we will discuss monitoring and scaling your application. For that, we'll use Amazon CloudWatch and Amazon EC2 Auto Scaling, alongside Elastic Load Balancing. We aren't going to focus on theory alone in this course. Instead, we will use a hands on example through a cloud-based application that will build over the duration of the course, piece by piece. The app we will build is an employee directory application that stores images and information about fictional employees in a company. There is no coding requirement for this course.

For all of the exercises, you'll use the AWS Management Console within your own AWS account. You will also have access to the source code, if you do want to explore further.

This course includes written segments we refer to as readings or notes to reinforce ideas, dive deeper into topics, as well as provide background information on concepts that we perhaps did not cover in the videos. Because of this, I highly suggest that you take the time to complete all of the readings to get the full benefit of the course. So again, welcome and as we say at Amazon, "Work hard, have fun, and make history."




Getting Started with AWS Cloud

Introduction to Week 1
Hey there. I hope you're excited to learn about cloud computing on AWS. I'm excited too, so let's go ahead and hop in. This week we are going to cover some of the foundational concepts that you'll need to know about when working with AWS.

Working with AWS is part theory part, technical knowledge, part vocabulary, and lots of practice and experimentation. This first week is going to help you establish a little bit from each of those categories. You will learn the theory behind cloud computing and the benefits of the cloud. This will help you make informed decisions about the cloud from a high level and give you some reasoning around why and when to use the cloud. Then we will dive in to the AWS global infrastructure, covering both regions and availability zones, followed by lessons on how to interact with AWS resources. This portion of the week is going to give you the technical knowledge and vocabulary that you need to create and discuss AWS architectures and properly understand AWS documentation and examples. A lot of what AWS offers can relate back to concepts used on traditional on-premises computing. And getting started with AWS means comparing those concepts to AWS concepts. After that, we will begin to discuss security and identity and access management. This is important to understand when you're getting started, because as soon as you create an AWS account, you'll have some actionable knowledge on how to secure that account right from the start. Starting off secure is a good place to be. Throughout all the topics this week and over the duration of the entire course, we will be using a sample Employee Directory web application to demonstrate how AWS services are used, and we'll be using the same application to give you some hands-on experience through exercises done in your own AWS account. Let's go ahead and take a look at the Employee Directory application.

You can see I am already in the browser and I have this Employee Directory application up and running. And what I want to do now is show you the functionality of this app. This is a basic CRUD app, or a Create, Read, Update, Delete application. This app keeps track of employees working within a company. So the first thing I want to do here is create a new employee. So to do that, I'm going to go ahead and click Add.

And then I'm going to give the employee a name. I'm just going to add myself here. My location is USA.

My title is Senior Cloud Technologist.

And then you have the ability to add some badges to employees. So I'm going to go ahead and select Mac User, Frequent Flier, and Coffee Snob for myself. So I'll go ahead and click Save. And then you can see now we have the saved banner popped up and we're back on the homepage. And I actually forgot to add a picture for myself, so I'm going to go ahead and click on the employee, and then I'm going to click the Edit button, and now I'm going to select a file here which is just a picture of me, and then I'll click Save.

And now we can see that this employee has a photo. One more thing that this app can do, is we can delete employees. So I'll go ahead and do that, and now you can see we have an empty directory again. And then one final thing to know about is we have something called an info page, and this gives some information about where the app is hosted, and this will come in handy later on in the course.

So, those are the features of the app from a user's perspective. Time to review now how we will build this app using AWS services. This application will be built in a private network using Amazon Virtual Private Cloud or VPC. We will host the application's backend code on Amazon Elastic Compute Cloud or EC2, which is a service that essentially offers virtual machines on AWS. So let's go ahead and add those service to our diagram as well. The employee data will be stored in a database which will also live inside of this network. And this will be hosted using a service called Amazon Relational Database Service or RDS, or we might be hosting it on Amazon DynamoDB. So we'll add both of these to our diagram. The images for the employees will be stored using the object storage service Amazon Simple Storage Service, or what we call S3, which will allow the unlimited storage of any file type like the images in this example. So these are the basic building blocks of our application, but we're not done yet. We are also going to use Amazon CloudWatch for monitoring the solution. And we want to ensure that our application is scalable and fault-tolerant. So I'm also going to add an Elastic Load Balancer here which will distribute the traffic across the EC2 instances. And we will also add Amazon EC2 Auto Scaling to this diagram, so that way our solution can scale out with demand and scale in when demand decreases.

For security and identity, we will be using Amazon Identity and Access Management or IAM. So you can see that there are a lot of different pieces on this diagram. But don't worry, we are going to build this app step-by-step using the AWS Management Console. We will add to this diagram, reference it, and change it throughout the course to meet our needs. And we're going to let it evolve as new ideas and techniques enter our world. One more thing to note about this course before I let you go. If you hear this noise, (blip) it means that you are going to be seeing one of our informational pop-ups on the screen, which convey extra information like word definitions, AWS best practices, tips and tricks or general commentary written for you by our lively furry sidekicks Meowzy and Kiwi. They know all the tips and are very helpful little friends to have around during this course. So that's it for now. Have fun and make sure you complete both exercises for this week so that you can start working hands-on with AWS.




Reading 1.2: What is AWS?
What is the Cloud? 
In the past, companies and organizations hosted and maintained hardware such as compute, storage, and networking equipment in their own data centers. They needed to allocate entire infrastructure departments to take care of them, resulting in a costly operation that made some workloads and experimentation impossible.

As internet usage became more widespread, the demand for compute, storage, and networking equipment increased. For some companies and organizations, the cost of maintaining a large physical presence was unsustainable. To solve this problem, cloud computing was created.

Cloud computing is the on-demand delivery of IT resources over the internet with pay-as-you-go pricing. You no longer have to manage and maintain your own hardware in your own data centers. Companies like AWS own and maintain these data centers and provide virtualized data center technologies and services to users over the internet.

To help differentiate between running workloads on-premises versus in the cloud, consider the scenario where your developers need to deploy a new feature on your application. Before they deploy, the team wants to test the feature in a separate quality assurance (QA) environment that has the exact same configurations as production.

If you run your application on-premises, creating this additional environment requires you to buy and install hardware, connect the necessary cabling, provision power, install operating systems, and more. All of these tasks can be time-consuming and take days to perform. Meanwhile, the new product feature’s time-to-market is increasing and your developers are waiting for this environment. 

If you ran your application in the cloud, you can replicate the entire environment as often as needed in a matter of minutes or even seconds. Instead of physically installing hardware and connecting cabling, you can logically manage your physical infrastructure over the internet. 

Using cloud computing not only saves you time from the set-up perspective, but it also removes the undifferentiated heavy lifting. If you look at any application, you’ll see that some of the aspects of it are very important to your business, like the code. However, there are other aspects that are no different than any other application you might make: for instance the compute the code runs on. By removing repetitive common tasks that don’t differentiate your business, like installing virtual machines, or storing backups, you can focus on what is strategically unique to your business and let AWS handle the tasks that are time consuming and don’t separate you from your competitors. 

So where does AWS fit into all of this? Well AWS simply just provides cloud computing services. Those IT resources mentioned in the cloud computing definition are AWS services in this case. We’ll need to use these AWS services to architect a scalable, highly available, and cost effective infrastructure to host our corporate directory application. This way we can get our corporate directory app out into the world quickly, without having to manage any heavy-duty physical hardware. There are the six main advantages to running your workloads on AWS.

The Six Benefits of Cloud Computing
Pay as you go. Instead of investing in data centers and hardware before you know how you are going to use them, you pay only when you use computing resources, and pay only for how much you use.

Benefit from massive economies of scale. By using cloud computing, you can achieve a lower cost than you can get on your own. Because usage from hundreds of thousands of customers is aggregated in the cloud, AWS can achieve higher economies of scale, which translates into lower pay as-you-go prices.
 
Stop guessing capacity. Eliminate guessing on your infrastructure capacity needs. When you make a capacity decision prior to deploying an application, you often end up either sitting on expensive idle resources or dealing with limited capacity. With cloud computing, these problems go away. You can access as much or as little capacity as you need, and scale up and down as required with only a few minutes notice.
 
Increase speed and agility. IT resources are only a click away, which means that you reduce the time to make those resources available to your developers from weeks to just minutes. This results in a dramatic increase in agility for the organization since the cost and time it takes to experiment and develop is significantly lower.
 
Stop spending money running and maintaining data centers. Focus on projects that differentiate your business, not the infrastructure. Cloud computing lets you focus on your customers, rather than on the heavy lifting of racking, stacking, and powering physical infrastructure. This is often referred to as undifferentiated heavy lifting.

Go global in minutes. Easily deploy your application in multiple Regions around the world with just a few clicks. This means you can provide lower latency and a better experience for your customers at a minimal cost.


https://aws.amazon.com/what-is-cloud-computing/
https://docs.aws.amazon.com/whitepapers/latest/aws-overview/types-of-cloud-computing.html
https://aws.amazon.com/what-is-aws/




AWS Global Infrastructure
For our employee directory application, we'll be using photos of each of our employees. We have to store them somewhere safe. Currently, the only copy of these photos are saved on my laptop right now. But if my laptop breaks, then what happens? No more photos. I want to make sure this doesn't happen, so I'm going to upload the photos to AWS to ensure that the copies exist even if my laptop is destroyed. This also allows me to access my photos from anywhere, my home, my phone, a plane, on a train, everywhere. When I store these photos in an AWS service, unbeknownst to me, I'm storing it in a data center somewhere and servers inside that data center. But if a natural disaster happens or a fire or let's say a giant lizard comes out of nowhere, stomps on the data center, then what do we do? Luckily, AWS has planned for this event, and many others, including natural disasters and other unavoidable accidents. 

The way they planned for it is through redundancy. AWS clusters data centers together around the world. So here, AWS might have a second data center connected to the first data center through redundant high speed and low latency links. That way, if the first data center goes down, the second data center is still up and running. This cluster of data centers is called an Availability Zone or AZ. An AZ consists of one or more data centers with redundant power, networking, and connectivity. Unfortunately, sometimes natural disasters like hurricanes or giant lizards might also extend to impacting an entire AZ, but AWS has planned for that too - - with redundancy. Like data centers, AWS also clusters AZs together and also connects them with redundant high speed and low-latency links. 

A cluster of AZs is simply called a region. In AWS, you get to choose the location of your resources by picking a region. Regions are generally named by location so you can easily tell where they are. For example, I could put our employee photos in a region in Northern Virginia called the N. Virginia Region. And remember, AWS is not going to name a region in Germany after Northern Virginia. As a basic rule, there are four aspects you need to consider when deciding which AWS region to use: compliance, latency, price, and service availability. Let's start with compliance. Before any other factors, you must first look at your compliance requirements. You might find that your application, company, or country that you live in requires you to handle your data and IT resources in a certain way. Do you have a requirement that your data must live in the UK boundaries? Then you should choose the London Region, full-stop. None of the rest of the factors even matter.

Or if you operate in Canada, then you may be required to run inside the Canada Central Region.

But if you don't have a compliance or regulatory control dictating your region, then you can look at the other factors. For example, our employee photos are not restricted by regulations, so I can continue looking at the next factor, which is latency.

Latency is all about about how close your IT resources are to your user base. If I want every employee around the world to be able to view the employee photos quickly, then I should place the infrastructure that hosts those photos close to my employees. We are all bound by the speed of light. Applied to your business, that means if all your users live in Oregon, then it makes sense to run your application in the Oregon Region. You could run it in the Brazil Region, but the latency from Oregon to Brazil might impact your users and creates slower load times.

But maybe I really want to run my application or store my employee photos in Brazil. One problem I might run into is the pricing, which is the next factor we'll talk about. The pricing can vary from region to region, so it may be that some regions like the Sao Paolo Region are more expensive than others due to different tax structures. So even if I wanted to store my employee photos in Brazil, it might not make sense from the latency perspective or the pricing perspective. And then finally, the fourth factor you'll want to consider is the services you want to use. Often when we create new services or new features in AWS, we don't roll out those services to every region we have right away. Meaning if you want to begin using a new service on Day One after it launches, then you'll want to make sure it operates in the region that you're looking at running your infrastructure in.

To recap, regions, availability zones, and data centers exist in a redundant nested sort of way. There are data centers inside availability zones and availability zones inside regions. And how do you choose a region? By looking at compliance, latency, pricing, and service availability.




Reading 1.3: AWS Global Infrastructure
Infrastructure, like data centers and networking connectivity, still exists as the foundation of every cloud application. In AWS, this physical infrastructure makes up the AWS Global Infrastructure, in the form of Availability Zones and Regions.

Regions
Regions are geographic locations worldwide where AWS hosts its data centers. AWS Regions are named after the location where they reside. For example, in the United States, there is a Region in Northern Virginia called the Northern Virginia Region and a Region in Oregon called the Oregon Region. There are Regions in Asia Pacific, Canada, Europe, the Middle East, and South America, and AWS continues to expand to meet the needs of its customers.

Each AWS Region is associated with a geographical name and a Region code. 
Here are a few examples of Region codes:
us-east-1: This is the first Region created in the east of the US. The geographical name for this Region is N. Virginia.
ap-northeast-1: The first Region created in the northeast of Asia Pacific. The geographical name for this Region is Tokyo.

AWS Regions are independent from one another. This means that your data is not replicated from one Region to another, without your explicit consent and authorization.


Choose the Right AWS Region
Consider four main aspects when deciding which AWS Region to host your applications and workloads: latency, price, service availability, and compliance.
Latency. If your application is sensitive to latency, choose a Region that is close to your user base. This helps prevent long wait times for your customers. Synchronous applications such as gaming, telephony, WebSockets, and IoT are significantly affected by higher latency, but even asynchronous workloads, such as ecommerce applications, can suffer from an impact on user connectivity.
 
Price. Due to the local economy and the physical nature of operating data centers, prices may vary from one Region to another. The pricing in a Region can be impacted by internet connectivity, prices of imported pieces of equipment, customs, real estate, and more. Instead of charging a flat rate worldwide, AWS charges based on the financial factors specific to the location.  
 
Service availability. Some services may not be available in some Regions. The AWS documentation provides a table containing the Regions and the available services within each one.
 
Data compliance. Enterprise companies often need to comply with regulations that require customer data to be stored in a specific geographic territory. If applicable, you should choose a Region that meets your compliance requirements.


Availability Zones
Inside every Region is a cluster of Availability Zones (AZ). An AZ consists of one or more data centers with redundant power, networking, and connectivity. These data centers operate in discrete facilities with undisclosed locations. They are connected using redundant high-speed and low-latency links.

AZs also have a code name. Since they’re located inside Regions, they can be addressed by appending a letter to the end of the Region code name. For example:
us-east-1a: an AZ in us-east-1 (Northern Virginia Region)
sa-east-1b: an AZ in sa-east-1 (São Paulo Region in South America)

If you see that a resource exists in us-east-1c, you know this resource is located in AZ c of the us-east-1 Region.


Scope AWS Services
Depending on the AWS Service you use, your resources are either deployed at the AZ, Region, or Global level. Each service is different, so you need to understand how the scope of a service may affect your application architecture. 

When you operate a Region-scoped service, you only need to select the Region you want to use. If you are not asked to specify an individual AZ to deploy the service in, this is an indicator that the service operates on a Region-scope level. For region-scoped services, AWS automatically performs actions to increase data durability and availability.

On the other hand, some services ask you to specify an AZ. With these services, you are often responsible for increasing the data durability and high availability of these resources.


Maintain Resiliency
To keep your application available, you need to maintain high availability and resiliency. A well-known best practice for cloud architecture is to use Region-scoped, managed services. These services come with availability and resiliency built in.

When that is not possible, make sure the workload is replicated across multiple AZs. At a minimum, you should use two AZs. If one entire AZ fails, your application will have infrastructure up and running in at least a second AZ to take over the traffic.


https://aws.amazon.com/about-aws/global-infrastructure/
https://aws.amazon.com/about-aws/global-infrastructure/regions_az/
https://docs.aws.amazon.com/whitepapers/latest/aws-overview/global-infrastructure.html
https://aws.amazon.com/about-aws/global-infrastructure/regions_az/
https://docs.aws.amazon.com/general/latest/gr/rande.html
https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/




Interacting with AWS
When you own the infrastructure, it's easy to understand how you interact with it because you can see it, touch it and work with it on every level. If I have a server that I've stood up in my closet, interacting with that server is easy because it's mine. I can touch it.

When I remove the ability for me to touch and see something, when the infrastructure becomes virtual, the way that I work with that infrastructure has to change a bit. Instead of physically managing my infrastructure, I now logically manage it through the AWS application programming interface or API. So now when I create, delete or change any AWS resource, whether it's a virtual server or a storage system for employee photos, I use API calls to AWS to do that. You can make these API calls in several ways but the three main ways we're going to talk about are the AWS Management Console, the AWS Command Line Interface and the AWS Software Development Kits or SDKs.

When people are first getting started with AWS, they'll typically use the AWS Management Console. This is a web-based console that you log into from your browser. The great thing about the console is that you can point and click. By simply clicking and following prompts, you can get started with some of the services without knowing anything about the service. With the console, there's no need to worry about scripting or finding the proper syntax. When you log into the console, the landing page will show you all of the possible services that you can work with organizing them into relevant categories, such as compute, databases, storage and more. On the upper right-hand corner is where you select the region you want to work in.

Changing the region, directs the browser to make requests to that region represented by a different URL. If I change the region to Paris, you're making requests to eu-west-3.console.aws.amazon.com or the Paris region's web console. After you work with the console for a while, you may want to move away from the manual creation of resources. For example, in the console, you have to go through multiple screens to set configurations to create a virtual machine. And if I wanted to create a second virtual machine, I would need to go through that process all over again. Well, this is helpful, it also leaves room for human error. I might miss a checkbox or misspell something or even skip important settings by accident.

So when you get more familiar with AWS or if you're working in a production environment that requires a degree of risk management, you should move to a tool that enables you to script or program these API calls. One of these tools is called the AWS Command Line Interface or CLI. You can download this tool and then use the terminal on your machine to create and configure AWS services. Instead of having a GUI to interact with like the console, you instead create commands using a defined AWS syntax. For example, if I wanted to launch a virtual machine, I first type in aws, which is how we know we interact with the API, then type in the service, in this case which is ec2,

the service that allows us to create and manage virtual machines, which we'll learn about later. And then the command that we want to perform in that service. And then any other configurations we want to set. One command versus multiple screens you have to click through in the console can help reduce accidental human errors but that also means you have to work with defined syntax and get that syntax correct in order for your command to run successfully. So there is some upfront cost in just understanding how to form commands but after a while, you can begin to script these commands out, making them repeatable which will save you time in the long run. The other tool that allows you to interact with the AWS API programmatically is the AWS Software Development Kits or SDKs. SDKs are created and maintained by AWS for the most popular programming languages, such as Python, Java, Node.js, .NET, Ruby and more.

This comes in handy when you want to integrate your application source code with AWS services. For example, our employee directory application runs using Python and Flask. If I wanted to store all the employee photos in an AWS storage service, I could use the Python SDK to write code to interact with the AWS storage service. The ability of managing AWS services from a place where you can run source code with conditions, loops, arrays, lists and other programming elements provides a lot of power and creativity. All right, that wraps up this video. To recap, you have three main options to connect with AWS, the console, the CLI and the SDKs. In this course will mainly be using the console to interact with the services, but feel free to challenge yourself by using the CLI if you're a bit more advanced.




Reading 1.4: Interacting with AWS
Every action you make in AWS is an API call that is authenticated and authorized. In AWS, you can make API calls to services and resources through the AWS Management Console, the AWS Command Line Interface (CLI), or the AWS Software Development Kits (SDKs). 


The AWS Management Console
One way to manage cloud resources is through the web-based console, where you log in and click on the desired service. This can be the easiest way to create and manage resources when you first begin working with the cloud. Below is a screenshot that shows the landing page when you first log into the AWS Management Console. 

The services are placed in categories, such as compute, database, storage and security, identity and compliance.

On the upper right corner is the Region selector. If you click it and change the Region, you will make requests to the services in the chosen Region. The URL changes, too. Changing the Region directs the browser to make requests to a whole different AWS Region, represented by a different subdomain.


The AWS Command Line Interface (CLI)
Consider the scenario where you run tens of servers on AWS for your application’s frontend. You want to run a report to collect data from all of these servers. You need to do this programmatically every day because the server details may change. Instead of manually logging into the AWS Management Console and copying/pasting information, you can schedule an AWS Command Line Interface (CLI) script with an API call to pull this data for you.

The AWS CLI is a unified tool to manage AWS services. With just one tool to download and configure, you control multiple AWS services from the command line and automate them with scripts. The AWS CLI is open-source, and there are installers available for Windows, Linux, and Mac OS. 
Here is an example of running an API call against a service using the AWS CLI: aws ec2 describe-instances
You get this response:
 
{
    "Reservations": [
        {
            "Groups": [],
            "Instances": [
                {
                    "AmiLaunchIndex": 0,

and so on.


AWS Software Development Kits (SDKs)
API calls to AWS can also be performed by executing code with programming languages. You can do this by using AWS Software Development Kits (SDKs). SDKs are open-source and maintained by AWS for the most popular programming languages, such as C++, Go, Java, JavaScript, .NET, Node.js, PHP, Python, and Ruby.

Developers commonly use AWS SDKs to integrate their application source code with AWS services. Let’s say the frontend of the application runs in Python and every time it receives a cat photo, it uploads that photo to a storage service. This action can be achieved from within the source code by using the AWS SDK for Python.

Here is an example of code you can implement to work with AWS resources using the Python AWS SDK.

import boto3
ec2 = boto3.client('ec2')
response = ec2.describe_instances()
print(response)


https://docs.aws.amazon.com/awsconsolehelpdocs/latest/gsg/learn-whats-new.html
https://aws.amazon.com/cli/
https://aws.amazon.com/tools/




Introduction to Exercise 1
It's time for your first hands-on exercise with AWS. Before you can begin building on AWS, you'll have to have an AWS account. So for your first exercise, we ask that you create an account with AWS, verify the account and then you'll set up some billing alerts. When you create an AWS account, you can then begin using the services and a lot of different AWS services offer a free tier. The free tier varies from service to service and all of the services that we chose for this course do have a free tier where you can use the resources for free with a limited capacity for a limited amount of time. If you have an existing AWS account that you are trying to use, there's a chance that you won't qualify for the free tier and would incur costs for the exercises that you complete in this course. So for this first exercise, it's going to be pretty straightforward and we are building up to the more complex tasks involved with hosting our employee directory application. You'll create and confirm your new AWS account, log in to that account and then you'll explore how to do some basic management tasks like where to find your account information, how to change regions using the management console and setting up those billing alerts. You will set up a billing alert just in case you create a resource and then you forget to turn it off or delete it. You'll at least be notified when you have hit a certain threshold in the account for cost. So that's it for now. And make sure you utilize the discussion forums to ask questions if you get stuck or want more information on a specific topic.




Security in the AWS Cloud

Security and the AWS Shared Responsibility Model
In order to begin using AWS effectively, it's important to understand how security works in the cloud. You already know that by using AWS, you won't be managing every single aspect of hosting your solutions. You'll rely on AWS to manage portions of your workload for you, taking care of that undifferentiated heavy lifting, like running the day-to-day of the operations of the data center and managing the various virtualization techniques employed to keep your AWS account isolated from say, my AWS account. So, the question is, who is ultimately responsible for security in AWS? Is it, A, you the customer or B, AWS? The answer? Well, the correct answer is "yes". Both you and AWS are responsible for securing your AWS environment. Let's explore this concept a little bit more. AWS follows something called the Shared Responsibility Model. We don't view solutions built on AWS as one singular thing to be secured. We see it as a collection of parts that build on each other. AWS is responsible for the security of some aspects and the others, you are responsible for their security. Together with both you and AWS following best practices, you have an environment that you can trust. Let's take a look at the Shared Responsibility Model diagram.

You can see, we have the responsibility of security broken into two groupings, you and AWS, each being responsible for different components. We describe AWS as being responsible for security of the cloud. For example, one piece of the puzzle AWS is responsible for, is the AWS Global Infrastructure. And when I say global infrastructure, I mean the physical infrastructure that the cloud is running on. This is iron and concrete, buildings with fences protected by security guards and various other security measures. It also includes the AWS global backbone or the private fiber cables that connect each AWS region to each other. Managing the security of these pieces is all on AWS. You don't need to worry about that as far as security goes. Then there is the infrastructure and various software components that run AWS services. This includes compute databases, storage and networking. AWS is also responsible for securing these services from the host operating system up through the virtualization layer. For example, let's say you want to host some virtual machines or VMs on the cloud. We primarily use the service Amazon EC2 for this use case. When you create a VM using EC2, AWS manages the physical host that the VM is placed on as well as everything up through the hypervisor level. If the host operating system or the hypervisor needed to be patched or updated, that is the responsibility of AWS. This is good news for you as the customer, as it greatly reduces the operational overhead and running a scalable and elastic solution, leveraging virtualization. We will talk more about EC2 and elastic solutions in upcoming lessons. For now, let's get back to the security aspect. So, if AWS manages the underlying hardware up through the virtualization layer, what are you responsible for? Well, you are responsible for security in the cloud, similar to how a construction company builds a building and it's on them to make sure that the building itself is stable and secure. Then, you can rent an apartment in that building. It's up to you lock the door to your apartment. Security of the building and security in the building are two different elements. For security in the cloud, the base layer is secured by AWS. It's up to you to lock the door. So for our EC2 example, you are responsible for tasks like patching the operating systems of your VMs, encrypting the data in transit and at rest, configuring firewalls and controlling who has access to these resources as well as controlling how much access they have. The main thing to understand is that you own your data in AWS.

You are ultimately responsible for ensuring that your data is encrypted, secure and has proper access controls in place. In many cases, AWS services offer native features that you can enable to achieve a secure solution. It's up to you to actually use them. In other cases, you may devise your own solutions to meet compliance and security standards for your own specific industry or use case. So, that's the Shared Responsibility Model at a high level. I do want you to keep something in mind though. There is some amount of nuance that you should understand as we move through this course regarding the Shared Responsibility Model. Each AWS service is different and serves a different purpose and a different use case. Therefore, the Shared Responsibility Model can vary from service to service as well. This is a good thing as you get to decide how to build your solutions on AWS.